{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx6Yi+AVWNQcZkM7YRlcyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khagendra-12/AdvancedPython/blob/main/AdvPyAsm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advance Python Assignments**"
      ],
      "metadata": {
        "id": "VEMSOnLJD49x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part I: Process Automation**"
      ],
      "metadata": {
        "id": "m3h5Jd1vECfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. Create a file that contains 1000 lines of random strings."
      ],
      "metadata": {
        "id": "_2NAIDK-EHxT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKGKYM3GDzDP",
        "outputId": "444b0043-db48-48d5-8176-a1d3c978641a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 Lines of random strings added to '1kstr.txt'.\n"
          ]
        }
      ],
      "source": [
        "import random as rad\n",
        "import string as s\n",
        "\n",
        "fp = open('1kstr.txt', 'w')\n",
        "for _ in range(1000):\n",
        "  words = []\n",
        "  for _ in range(rad.randint(5, 10)):\n",
        "    radstr = ''.join(rad.choices(s.ascii_letters, k=rad.randint(3, 12)))\n",
        "    words.append(radstr)\n",
        "  radsen = ' '.join(words)\n",
        "  fp.write(f\"{radsen}\\n\")\n",
        "fp.close\n",
        "print(\"1000 Lines of random strings added to '1kstr.txt'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. Create a file that contains multiple lines of random strings and file size must be 5 MB."
      ],
      "metadata": {
        "id": "WVEobFZmK61n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random as rad\n",
        "import string as s\n",
        "\n",
        "fp = open('5MB.txt', 'w')\n",
        "\n",
        "while os.path.getsize('5MB.txt') < (5 *1024 *1024):\n",
        "  words = []\n",
        "  for _ in range(rad.randint(5, 10)):\n",
        "    radstr = ''.join(rad.choices(s.ascii_letters, k=rad.randint(3, 12)))\n",
        "    words.append(radstr)\n",
        "  radsen = ' '.join(words)\n",
        "  fp.write(f\"{radsen}\\n\")\n",
        "fp.close()\n",
        "\n",
        "print(\"Created a file with less than 5MB of data with random strings.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhA69REULBdH",
        "outputId": "a96848cc-f758-49c6-852d-38b0a1e083de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a file with less than 5MB of data with random strings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. Create 10 files that contains multiple lines of random strings and file size of each file must be 5 MB.\n"
      ],
      "metadata": {
        "id": "V6cayg26NEPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random as rad\n",
        "import string as s\n",
        "\n",
        "def file5MB(x):\n",
        "  filen = f\"5MB({x}).txt\"\n",
        "  fp = open(filen, 'w')\n",
        "  while os.path.getsize(filen) < (5 *1024 *1024):\n",
        "    words = []\n",
        "    for _ in range(rad.randint(5, 10)):\n",
        "      radstr = ''.join(rad.choices(s.ascii_letters, k=rad.randint(3, 12)))\n",
        "      words.append(radstr)\n",
        "    radsen = ' '.join(words)\n",
        "    fp.write(f\"{radsen}\\n\")\n",
        "  fp.close()\n",
        "\n",
        "for i in range (1,11):\n",
        "  file5MB(i)\n",
        "\n",
        "print(\"Created 10 files with less than 5MB of data with random strings.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFjG9Z-rNM3K",
        "outputId": "b2d499a5-e10c-4452-8378-4442036c8510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 10 files with less than 5MB of data with random strings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. Create 5 files of size 1GB, 2GB, 3GB, 4GB and 5GB; file contains multiple lines of random strings."
      ],
      "metadata": {
        "id": "HYdOM-tQPTfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random as rad\n",
        "import string as s\n",
        "\n",
        "def fileGB(x):\n",
        "  filen = f\"{x}GB.txt\"\n",
        "  with open(filen, 'w') as fp:\n",
        "    while os.path.getsize(filen) < (x *1024 *1024 *1024):\n",
        "      words = []\n",
        "      for _ in range(rad.randint(5, 10)):\n",
        "        radstr = ''.join(rad.choices(s.ascii_letters, k=rad.randint(3, 12)))\n",
        "        words.append(radstr)\n",
        "      radsen = ' '.join(words)\n",
        "      fp.write(f\"{radsen}\\n\")\n",
        "\n",
        "for i in range (1,6):\n",
        "  print(f\"Creating {i}GB file...\")\n",
        "  fileGB(i)\n",
        "  print(f\"{i}GB.txt created.\")\n",
        "\n",
        "print(\"Created files with 1GB, 2GB, 3GB, 4GB and 5GB of data with random strings.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhJQPeGvPY3e",
        "outputId": "5471e6dc-6540-4cd0-b6c9-977d778dc57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating 1GB file...\n",
            "1GB.txt created.\n",
            "Created files with 1GB, 2GB, 3GB, 4GB and 5GB of data with random strings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. Convert all the files of Q4 into upper case one by one."
      ],
      "metadata": {
        "id": "t_2j_IMNTsy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upfile(x):\n",
        "  filen = f\"{x}GB.txt\"\n",
        "  with open(filen, 'r') as fp:\n",
        "    text = fp.read()\n",
        "    uppertxt = text.upper()\n",
        "  with open(filen, 'w') as fp:\n",
        "    fp.write(uppertxt)\n",
        "\n",
        "for i in range (1,6):\n",
        "  print(f\"Converting {i}GB file to uppercase...\")\n",
        "  upfile(i)\n",
        "  print(f\"{i}GB.txt converted to uppercase.\")\n",
        "\n",
        "print(\"Converted files with 1GB, 2GB, 3GB, 4GB and 5GB of data with random strings to upper-case.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNfTSBjiU8hf",
        "outputId": "a2eff2cd-3c06-4933-80ab-3fa6e6ceb70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting 1GB file to uppercase...\n",
            "1GB.txt converted to uppercase.\n",
            "Converted files with 1GB, 2GB, 3GB, 4GB and 5GB of data with random strings to upper-case.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6. Convert all the files of Q4 into upper case parallel using multi-threading."
      ],
      "metadata": {
        "id": "Ctid5OS4bkd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating files using threading."
      ],
      "metadata": {
        "id": "s_4oEYc0djYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random as rad\n",
        "import string as s\n",
        "import threading\n",
        "\n",
        "def fileGB(x):\n",
        "  filen = f\"{x}GB.txt\"\n",
        "  print(f\"Creating file with {x}GB of data.\")\n",
        "  with open(filen, 'w') as fp:\n",
        "    while os.path.getsize(filen) < (x *1024 *1024 *1024):\n",
        "      words = []\n",
        "      for _ in range(rad.randint(5, 10)):\n",
        "        radstr = ''.join(rad.choices(s.ascii_letters, k=rad.randint(3, 12)))\n",
        "        words.append(radstr)\n",
        "      radsen = ' '.join(words)\n",
        "      fp.write(f\"{radsen}\\n\")\n",
        "    print(f\"File with {x}GB of data created.\")\n",
        "\n",
        "files = []\n",
        "for i in range(1,6):\n",
        "  create = threading.Thread(target=fileGB, args=(i,))\n",
        "  files.append(create)\n",
        "  create.start()\n",
        "\n",
        "for i in files:\n",
        "  i.join()\n",
        "\n",
        "print(\"Created files containg 1GB, 2GB, 3GB, 4GB and 5GB of data using threading.\")"
      ],
      "metadata": {
        "id": "lfLlhjeoboLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a24263-f6e9-4da2-9ce6-3b4eb6b30e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating file with 1GB of data.\n",
            "Creating file with 2GB of data.\n",
            "Creating file with 3GB of data.\n",
            "File with 2GB of data created.\n",
            "Creating file with 4GB of data.\n",
            "Creating file with 5GB of data.\n",
            "File with 1GB of data created.\n",
            "File with 3GB of data created.\n",
            "File with 4GB of data created.\n",
            "File with 5GB of data created.\n",
            "Created files containg 1GB, 2GB, 3GB, 4GB and 5GB of data using threading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting files to uppercase using threading."
      ],
      "metadata": {
        "id": "mtHmhPAKdoDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upfile(x):\n",
        "  filen = f\"{x}GB.txt\"\n",
        "  print(f\"Reading file with {x}GB of data.\")\n",
        "  with open(filen, 'r') as fp:\n",
        "    text = fp.read()\n",
        "    uppertxt = text.upper()\n",
        "  print(f\"Converting file with {x}GB of data to uppercase.\")\n",
        "  with open(filen, 'w') as fp:\n",
        "    fp.write(uppertxt)\n",
        "  print(f\"Converted file with {x}GB of data to uppercase.\")\n",
        "\n",
        "upperfiles = []\n",
        "for i in range(1,6):\n",
        "  upper = threading.Thread(target=upfile, args=(i,))\n",
        "  upperfiles.append(upper)\n",
        "  upper.start()\n",
        "\n",
        "for i in upperfiles:\n",
        "  i.join()\n",
        "\n",
        "print(\"Converted files with 1GB, 2GB, 3GB, 4GB and 5GB of data to uppercase using threading.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56EsdAK8dfRQ",
        "outputId": "40f5c2e2-865e-4016-cf32-c2bf891bf617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading file with 1GB of data.\n",
            "Converting file with 1GB of data to uppercase.\n",
            "Reading file with 2GB of data.\n",
            "Reading file with 3GB of data.\n",
            "Reading file with 4GB of data.\n",
            "Reading file with 5GB of data.\n",
            "Converted file with 1GB of data to uppercase.\n",
            "Converting file with 3GB of data to uppercase.\n",
            "Converting file with 4GB of data to uppercase.\n",
            "Converted file with 4GB of data to uppercase.\n",
            "Converting file with 5GB of data to uppercase.\n",
            "Converted file with 3GB of data to uppercase.\n",
            "Converted file with 5GB of data to uppercase.\n",
            "Converting file with 2GB of data to uppercase.\n",
            "Converted file with 2GB of data to uppercase.\n",
            "Converted files with 1GB, 2GB, 3GB, 4GB and 5GB of data to uppercase using threading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7. WAP to automatically download 10 images of cat from “Google Images”. [Hint: Find the package from\n",
        "pypi.org and use it]\n"
      ],
      "metadata": {
        "id": "CLYXcGYIvVqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from icrawler.builtin import GoogleImageCrawler\n",
        "\n",
        "googlepics = GoogleImageCrawler(storage = {'root_dir': 'catpics'})\n",
        "googlepics.crawl(keyword = 'cat', max_num = 10)\n",
        "print(\"Downloaded 10 images of cat from Google Images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fw3yB01vaKa",
        "outputId": "8a5aea8b-14f6-4ad1-d99e-5a78be0d4350"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 10 images of cat from Google Images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8. WAP to automatically download 10 videos of “Machine Learning” from “Youtube.com”. [Hint: Find the package from pypi.org and use it]"
      ],
      "metadata": {
        "id": "NyBrCRNVvFtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "from youtubesearchpython import VideosSearch\n",
        "import os\n",
        "\n",
        "videos_search = VideosSearch(\"Machine Learning\", limit=10)\n",
        "results = videos_search.result()[\"result\"]\n",
        "\n",
        "os.makedirs(\"MLVids\")\n",
        "\n",
        "for i, video in enumerate(results):\n",
        "    url = video['link']\n",
        "    title = video['title']\n",
        "    print(f\"\\nDownloading ({i+1}/10): {title}\")\n",
        "\n",
        "    try:\n",
        "        yt = YouTube(url)\n",
        "        vids = yt.streams.filter(progressive=True, file_extension='mp4').get_lowest_resolution()\n",
        "        vids.download(output_path=\"MLVids\")\n",
        "        print(\"Downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download: {e}\")\n"
      ],
      "metadata": {
        "id": "86qgiUAZvKDW",
        "outputId": "39256a4c-74ef-4c84-d459-4dda6df7092e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "post() got an unexpected keyword argument 'proxies'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3612266204>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvideos_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideosSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Machine Learning\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideos_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtubesearchpython/search.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, query, limit, language, region, timeout)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchMode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSearchMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getComponents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchMode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtubesearchpython/core/search.py\u001b[0m in \u001b[0;36msync_create\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msync_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_makeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parseSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtubesearchpython/core/search.py\u001b[0m in \u001b[0;36m_makeRequest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_makeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getRequestBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyncPostRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtubesearchpython/core/requests.py\u001b[0m in \u001b[0;36msyncPostRequest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msyncPostRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         return httpx.post(\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muserAgent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: post() got an unexpected keyword argument 'proxies'"
          ]
        }
      ]
    }
  ]
}